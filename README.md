# PresentAI - Intelligente Interaktive PrÃ¤sentationsplattform

![logo](screen.png)

PresentAI ist eine moderne, KI-gestÃ¼tzte Webanwendung fÃ¼r interaktive PrÃ¤sentationen mit innovativer **geteilter Architektur**. Die Plattform erstellt statische Info-Seiten vom PrÃ¤sentator und dynamische Feedback-Bereiche von ZuhÃ¶rern - vollstÃ¤ndig getrennt und intelligent verwaltet. Mit fortschrittlicher KI-Integration, festen Verarbeitungsintervallen und kompakter Feedback-Darstellung bietet PresentAI eine nahtlose Erfahrung fÃ¼r moderne PrÃ¤sentationen.

## ğŸ¯ Hauptfunktionen

### Innovative Geteilte Architektur
- **Statische Info-Seite**: Einmalig generiert aus Titel, Beschreibung und Abstract - bleibt unverÃ¤ndert
- **Dynamischer Feedback-Bereich**: Separate Sektion fÃ¼r ZuhÃ¶rer-Feedback mit automatischer Kategorisierung
- **Klare Trennung**: Info-Inhalte und Feedback-Inhalte sind vollstÃ¤ndig getrennt
- **ErgÃ¤nzungs-System**: Neue Feedbacks werden intelligent zu bestehenden Inhalten hinzugefÃ¼gt
- **ZusÃ¤tzliche Informationen**: PrÃ¤sentierende kÃ¶nnen jederzeit zusÃ¤tzliche Infos (z.B. Antworten auf Fragen) hinzufÃ¼gen
- **Live-Info-Freigabe**: Kontrollierte Sichtbarkeit der Live-Infoseite fÃ¼r ZuhÃ¶rer

### KI-gestÃ¼tzte Inhaltsgenerierung
- **Vollautomatische Kategorisierung**: KI Ã¼bernimmt komplette Feedback-Klassifizierung ohne Code-Regeln
- **Intelligente Zusammenfassung**: Ã„hnliche Fragen/Kommentare werden automatisch gruppiert
- **Sichere Link-Behandlung**: ALLE URLs landen in separater "âš ï¸ UngeprÃ¼fte Links" Sektion mit Beschreibungen
- **Flexible KI-Modelle**: UnterstÃ¼tzung fÃ¼r GPT-4, GPT-4.1-mini und andere Modelle
- **Automatische Content-Bereinigung**: Markdown-Optimierung fÃ¼r saubere Darstellung

### Robuste Fehlerbehandlung
- **Kontext-Erhaltung**: Bei API-Fehlern bleibt der bestehende Inhalt sichtbar
- **Intelligente Retry-Mechanismen**: Automatische Wiederholungsversuche mit konfigurierbaren VerzÃ¶gerungen
- **Manuelle Retry-Funktion**: PrÃ¤sentatoren kÃ¶nnen fehlgeschlagene KI-Aufrufe manuell erneut starten
- **Transparente Fehlermeldungen**: Klare Kommunikation bei Problemen

### Erweiterte Sicherheit
- **Content-Filterung**: Automatische Entfernung unangemessener oder beleidigender Inhalte
- **Soft-Delete System**: GelÃ¶schte PrÃ¤sentationen bleiben in der Datenbank erhalten
- **Audit-Trail**: VollstÃ¤ndige Nachverfolgung von LÃ¶schungen und Ã„nderungen

### Echtzeit-Interaktion
- **Feste Verarbeitungsintervalle**: Garantierte Verarbeitung alle 30 Sekunden (konfigurierbar)
- **Nie verzÃ¶gerte Verarbeitung**: Auch bei Dauerfeuer-Feedback erfolgt pÃ¼nktliche Verarbeitung
- **Kompakte Feedback-Anzeige**: Status-Symbole (âœ… verarbeitet, â³ wartend) fÃ¼r bessere Ãœbersicht
- **Batch-Verarbeitung**: Effiziente Sammlung mehrerer Feedbacks pro Intervall
- **Live-Updates**: Automatische Aktualisierung ohne manuelles Neuladen
- **QR-Code Integration**: Einfacher Zugang fÃ¼r ZuhÃ¶rer
- **Teilnehmer-Namen**: Optionale Namenserfassung mit localStorage fÃ¼r wiederholte Nutzung

### Erweiterte PrÃ¤sentator-Kontrolle
- **Einzelnes Feedback lÃ¶schen**: UnerwÃ¼nschte Feedbacks direkt aus der Liste entfernen
- **Feedback-Verarbeitung zurÃ¼cksetzen**: Alle verarbeiteten Feedbacks wieder auf wartend stellen
- **ZusÃ¤tzliche Informationen**: Jederzeit neue Infos zum statischen Bereich hinzufÃ¼gen
- **Live-Info-Freigabe**: Ein/Ausblenden der Live-Infoseite fÃ¼r ZuhÃ¶rer per Knopfdruck
- **Feedback-Sperrung**: TemporÃ¤res Blockieren neuer Feedbacks von ZuhÃ¶rern

## ğŸ› ï¸ Systemanforderungen

- Python 3.8 oder hÃ¶her
- Flask 2.0+
- SQLAlchemy
- OpenAI API-Zugang (GPT-4, GPT-4.1-mini, oder GPT-4o-mini)
- Font Awesome 6.0+ fÃ¼r Status-Icons
- **Gunicorn** fÃ¼r Produktionsumgebung (parallele Zugriffe)
- Weitere AbhÃ¤ngigkeiten siehe `requirements.txt`

## ğŸš€ Installation

### 1. Repository vorbereiten
```bash
git clone <repository-url>
cd ConfChat
```

### 2. Virtuelle Umgebung einrichten
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

### 3. AbhÃ¤ngigkeiten installieren
```bash
pip install -r requirements.txt
```

### 4. Umgebungsvariablen konfigurieren
```bash
# Erforderlich
export OPENAI_API_KEY=ihr-openai-api-schlÃ¼ssel

# Optional (wird automatisch generiert wenn nicht gesetzt)
export REGISTRATION_PASSWORD=ihr-registrierungspasswort
export SECRET_KEY=ihr-geheimer-schlÃ¼ssel
```

**Wichtig**: Das `REGISTRATION_PASSWORD` wird beim ersten Start automatisch generiert und in der Konsole angezeigt, falls nicht gesetzt.

### 5. Datenbank migrieren (falls erforderlich)
```bash
python migrate_db.py
```

### 6. Anwendung starten

#### Entwicklungsumgebung
```bash
python app.py
```

#### Produktionsumgebung (empfohlen)

**Linux/macOS/WSL:**
```bash
# Minimal-Setup fÃ¼r parallele Zugriffe
./start_production.sh

# Erweiterte Konfiguration (hÃ¶here Performance):
./start_production_advanced.sh

# Oder manuell:
python -m gunicorn --workers 1 --threads 4 --bind 0.0.0.0:5000 app:app
```

**Windows (ohne WSL):**
```cmd
# Windows-kompatible LÃ¶sung mit Waitress (Port 8000)
start_production.bat

# Oder manuell:
python -m pip install waitress
python -m waitress --host=127.0.0.1 --port=8000 --threads=4 app:app
```

**Hinweis:** Port 5000 ist unter Windows oft gesperrt. Das Windows-Skript verwendet daher Port 8000. Bei Problemen siehe `WINDOWS_TROUBLESHOOTING.md`.

#### Docker (empfohlen fÃ¼r Produktion)
```bash
# Mit Environment-Datei
cp .env.example .env
# .env bearbeiten und OPENAI_API_KEY setzen
docker-compose up -d

# Oder mit docker-run.sh Skript
OPENAI_API_KEY=sk-... ./docker-run.sh --port 8080

# Oder manuell
docker run -d \
  -p 8080:5000 \
  -e OPENAI_API_KEY=sk-... \
  -v $(pwd)/instance:/app/instance \
  ghcr.io/ihrusername/confchat:latest
```

### 7. Zugriff
- **Entwicklung:** http://127.0.0.1:5000/
- **Linux/macOS/WSL:** http://0.0.0.0:5000/
- **Windows:** http://127.0.0.1:8000/
- **Docker:** http://localhost:8080/ (oder gewÃ¤hlter Port)

## ğŸ“ Projektstruktur

```
ConfChat/
â”œâ”€â”€ app.py                      # Hauptanwendung (Flask)
â”œâ”€â”€ migrate_db.py              # Datenbank-Migrierungsskript
â”œâ”€â”€ Dockerfile                 # Docker-Image fÃ¼r Produktion
â”œâ”€â”€ docker-compose.yml         # Docker-Compose fÃ¼r lokale Entwicklung
â”œâ”€â”€ docker-run.sh              # Docker-Start-Skript mit Optionen
â”œâ”€â”€ .env.example               # Umgebungsvariablen-Vorlage
â”œâ”€â”€ start_production.sh        # Produktions-Start-Skript (Linux/macOS/WSL)
â”œâ”€â”€ start_production_advanced.sh # Erweiterte Produktions-Konfiguration (Linux/macOS/WSL)
â”œâ”€â”€ start_production.bat       # Windows-Produktions-Start-Skript (Port 8000)
â”œâ”€â”€ WINDOWS_TROUBLESHOOTING.md # Windows-spezifische ProblemlÃ¶sungen
â”œâ”€â”€ requirements.txt           # Python-AbhÃ¤ngigkeiten
â”œâ”€â”€ CLAUDE.md                  # Entwickler-Dokumentation
â”œâ”€â”€ instance/
â”‚   â””â”€â”€ presentations.db      # SQLite-Datenbank
â”œâ”€â”€ templates/                 # Jinja2-Templates
â”‚   â”œâ”€â”€ base.html             # Basis-Layout
â”‚   â”œâ”€â”€ dashboard.html        # PrÃ¤sentations-Dashboard
â”‚   â”œâ”€â”€ view_presentation.html # PrÃ¤sentations-Manager
â”‚   â”œâ”€â”€ public_view.html      # Ã–ffentliche ZuhÃ¶rer-Ansicht
â”‚   â””â”€â”€ ...                   # Weitere Templates
â”œâ”€â”€ static/                    # Statische Dateien
â””â”€â”€ test_*.py                 # Test-Suiten
```

## ğŸ­ Verwendung

### FÃ¼r PrÃ¤sentatoren

1. **Registrierung/Anmeldung**
   - Erster Benutzer wird automatisch als Admin eingerichtet
   - Nutzen Sie das generierte Registrierungspasswort

2. **PrÃ¤sentation erstellen**
   - Titel, Beschreibung, Kontext und Hauptinhalt eingeben
   - KI generiert automatisch statische Info-Seite (einmalig)

3. **ZuhÃ¶rer einladen**
   - QR-Code oder direkten Link teilen
   - ZuhÃ¶rer erhalten Zugang zur Live-Infoseite

4. **Feedback verwalten**
   - Kompakte Ãœbersicht mit Status-Symbolen (âœ… verarbeitet, â³ wartend)
   - Teilnehmer-Namen werden angezeigt falls angegeben
   - Automatische Verarbeitung alle 30 Sekunden (garantiert)
   - Manuelle Retry-Funktion bei KI-Problemen
   - Vollautomatische KI-Kategorisierung ohne manuelle Regeln
   - **Einzelne Feedbacks lÃ¶schen**: UnerwÃ¼nschte BeitrÃ¤ge direkt entfernen
   - **Feedback-Reset**: Alle Feedbacks wieder auf wartend stellen

5. **ZusÃ¤tzliche Informationen verwalten**
   - Neue Informationen jederzeit zum statischen Bereich hinzufÃ¼gen
   - Automatische Integration in die Live-Infoseite
   - Zeitstempel fÃ¼r bessere Nachverfolgung

6. **Live-Info-Freigabe kontrollieren**
   - Per Default ausgeblendet fÃ¼r ZuhÃ¶rer
   - Ein-Klick-Freigabe fÃ¼r Live-Infoseite
   - Sofortige Sichtbarkeit/Verbergung fÃ¼r alle ZuhÃ¶rer

7. **Feedback-Kontrolle**
   - Ein-Klick-Sperrung neuer Feedbacks von ZuhÃ¶rern
   - TemporÃ¤re Blockierung unabhÃ¤ngig von Live-Info-Freigabe
   - Klare Benachrichtigung fÃ¼r ZuhÃ¶rer bei gesperrtem Feedback

### FÃ¼r ZuhÃ¶rer

1. **Zugang Ã¼ber QR-Code oder Link**
2. **Namen eingeben (einmalig)**
   - Name wird im Browser gespeichert fÃ¼r zukÃ¼nftige Feedbacks
   - Erscheint in der Presenter-Ansicht fÃ¼r bessere Zuordnung
3. **Live-Infoseite betrachten** (nur wenn freigegeben)
   - Statische Info-Seite vom PrÃ¤sentator
   - ZusÃ¤tzliche Informationen vom PrÃ¤sentator
   - Dynamischer Feedback-Bereich von anderen ZuhÃ¶rern
   - Automatisch aktualisierte Inhalte alle 10 Sekunden
   - Strukturierte Darstellung mit Markdown-Formatierung
   - Nur sichtbar wenn PrÃ¤sentator die Live-Info freigegeben hat
4. **Interaktion**
   - Fragen stellen (landen in "Offene Fragen")
   - Links teilen (erscheinen in "âš ï¸ UngeprÃ¼fte Links" mit Beschreibung)
   - Faktische Informationen beitragen
   - Kommentare abgeben
   - **Hinweis**: Bei gesperrtem Feedback wird eine entsprechende Meldung angezeigt

## âš™ï¸ Erweiterte Konfiguration

### Feedback-Verarbeitung
```python
# In app.py anpassbar
FEEDBACK_PROCESSING_INTERVAL = 30  # Feste Verarbeitungsintervalle (Sekunden)
CLIENT_REFRESH_INTERVAL = 20       # Client-Aktualisierungsintervall
```

**Neue Architektur**:
- **Feste Zeitslots**: Verarbeitung erfolgt zu festen Zeiten (z.B. :00, :30 jeder Minute)
- **Garantierte Verarbeitung**: Auch bei kontinuierlichem Feedback wird pÃ¼nktlich verarbeitet
- **Kein Verschieben**: Neue Feedbacks verschieben die Verarbeitung nicht

### Retry-Mechanismen
- **Automatische VerzÃ¶gerung**: 10 Sekunden nach API-Fehlern
- **Kontext-Erhaltung**: Bestehende Inhalte bleiben bei Fehlern sichtbar
- **Manuelle Kontrolle**: Retry-Button fÃ¼r PrÃ¤sentatoren

### Content-Filterung & KI-Integration
- **Vollautomatische Filterung**: KI Ã¼bernimmt komplette Spam/Beleidigung-Erkennung
- **Intelligente Kategorisierung**: Fragen, Links, Fakten, Kommentare werden automatisch sortiert
- **Sichere Link-Behandlung**: Alle URLs landen zwingend in "âš ï¸ UngeprÃ¼fte Links" Sektion
- **Zusammenfassung**: Ã„hnliche Feedbacks werden intelligent gruppiert
- **Markdown-Bereinigung**: Entfernung stÃ¶render Code-Block-Markierungen
- **Flexible KI-Modelle**: GPT-4, GPT-4.1-mini, GPT-4o-mini unterstÃ¼tzt

## ğŸ”§ Entwicklung & Erweiterung

### Wichtige Komponenten

1. **Geteilte KI-Integration**
   - `generate_static_info_content()`: Einmalige Info-Seiten-Generierung
   - `generate_feedback_content()`: Dynamische Feedback-Verarbeitung
   - Vollautomatische KI-Kategorisierung ohne Code-Regeln
   - ErgÃ¤nzungs-System statt Neugenerierung

2. **Feste Intervall-Verarbeitung**
   - Zeitslot-basierte Verarbeitung (z.B. alle 30 Sekunden)
   - Garantierte PÃ¼nktlichkeit auch bei Dauerfeuer-Feedback
   - Thread-basierte Background-Verarbeitung
   - Intelligente Warteschlangen-Verwaltung

3. **Soft-Delete System**
   - PrÃ¤sentationen werden als gelÃ¶scht markiert, bleiben aber in DB
   - VollstÃ¤ndiger Audit-Trail mit Teilnehmer-Namen
   - Wiederherstellbarkeit

### Tests ausfÃ¼hren
```bash
# Einzelne Tests
python test_improved_prompt.py
python test_soft_delete.py
python test_markdown_filter.py

# Alle Tests
python -m pytest test_*.py
```

### Demo-Skripte
```bash
python demo_improved_prompt.py    # Feedback-Kategorisierung
python demo_soft_delete.py        # Soft-Delete Verhalten
python demo_improved_behavior.py  # Fehlerbehandlung
```

## ğŸš€ Produktionsdeployment

### Docker (Empfohlen)

**Schnellstart mit Docker:**
```bash
# 1. Repository klonen
git clone <your-repo-url>
cd ConfChat

# 2. Umgebungsvariablen setzen
cp .env.example .env
# .env bearbeiten und OPENAI_API_KEY setzen

# 3. Starten
docker-compose up -d
```

**Erweiterte Docker-Optionen:**
```bash
# Mit docker-run.sh (mehr Kontrolle)
OPENAI_API_KEY=sk-... ./docker-run.sh --port 8080 --detach

# GitHub Container Registry Image verwenden
docker run -d \
  -p 8080:5000 \
  -e OPENAI_API_KEY=sk-... \
  -v $(pwd)/instance:/app/instance \
  ghcr.io/ihrusername/confchat:latest

# Container-Management
./docker-run.sh --logs    # Logs anzeigen
./docker-run.sh --stop    # Container stoppen
```

**GitHub Actions Setup:**
1. Repository auf GitHub pushen
2. Actions werden automatisch ausgefÃ¼hrt
3. Docker-Image wird in GitHub Container Registry gepusht
4. Image URL: `ghcr.io/ihrusername/confchat:latest`

### Minimal-Setup fÃ¼r parallele Zugriffe (ohne Docker)

Das mitgelieferte Produktions-Setup verbessert die Performance erheblich:

```bash
# Einfacher Start (empfohlen)
./start_production.sh

# Erweiterte Konfiguration (mehr Performance, kleines Risiko)
./start_production_advanced.sh
```

**Vorteile gegenÃ¼ber `python app.py`:**
- **4x bessere Parallelverarbeitung** durch Multi-Threading
- **Robustheit** bei Worker-Crashes
- **Produktions-optimierte Konfiguration**
- **Bessere Ressourcennutzung**

### Performance-Vergleich

| Setup | Concurrent Users | Threading | StabilitÃ¤t | Empfehlung |
|-------|------------------|-----------|------------|------------|
| `python app.py` | ~10-20 | Entwicklungsserver | Niedrig | Nur Entwicklung |
| **Docker** | ~500-1000+ | Gunicorn + Container | **Sehr hoch** | **âœ… Produktion** |
| `start_production.sh` | ~100-200 | 1 Worker + 4 Threads | Hoch | Einfache Prod |
| `start_production_advanced.sh` | ~200-500 | 2 Worker + 2 Threads | Mittel* | Erfahrene Nutzer |

*\*Risiko: Background-Processing kÃ¶nnte doppelt ausgefÃ¼hrt werden*

**Docker-Vorteile:**
- **Isolation**: Keine AbhÃ¤ngigkeitskonflikte
- **PortabilitÃ¤t**: LÃ¤uft Ã¼berall gleich
- **Skalierung**: Einfache Horizontal-Skalierung
- **CI/CD**: Automatisches Building und Deployment
- **Wartung**: Container-Updates ohne Server-Neustart

### Erweiterte Produktions-Optionen

FÃ¼r hÃ¶here Skalierung siehe Vollarchitektur-Empfehlungen:
- **PostgreSQL** statt SQLite (>500 concurrent users)
- **Celery** fÃ¼r Background-Tasks (eliminiert Threading-Probleme)
- **Redis** fÃ¼r Session-Storage bei Multi-Worker Setup
- **Nginx** als Reverse Proxy fÃ¼r statische Dateien

## ğŸ¨ Anpassungen

### KI-Provider wechseln
Die Anwendung unterstÃ¼tzt verschiedene KI-APIs:
- **OpenAI GPT-4** (beste QualitÃ¤t)
- **OpenAI GPT-4.1-mini** (optimiert)
- **OpenAI GPT-4o-mini** (kostengÃ¼nstig)
- **Claude** (Anthropic) - anpassbar
- **Google Gemini** - anpassbar
- **Hugging Face** - anpassbar

Einfach das `model`-Feld in den API-Aufrufen Ã¤ndern.

### UI-Anpassungen
- Templates in `templates/` Verzeichnis
- Bootstrap 4 + Font Awesome 6 fÃ¼r responsives Design
- Kompakte Feedback-Anzeige mit Status-Symbolen
- Erweiterbare CSS-Klassen

### FunktionalitÃ¤ts-Erweiterungen
- WebSocket-Integration fÃ¼r Echtzeit-Chat
- Datei-Upload fÃ¼r PrÃ¤sentationen
- Erweiterte Benutzerverwaltung
- Export-Funktionen (PDF, Word)

## ğŸ›¡ï¸ Sicherheit

- **Eingabe-Validierung**: Schutz vor Injection-Angriffen
- **Content-Filterung**: Automatische Moderation
- **Session-Management**: Sichere Benutzer-Sessions
- **API-SchlÃ¼ssel-Schutz**: Umgebungsvariablen fÃ¼r sensible Daten

## ğŸ“Š Monitoring & Debugging

- **Konsolen-Logging**: Detaillierte Logs fÃ¼r Debugging
- **Error-Tracking**: VollstÃ¤ndige Fehlerprotokollierung
- **Performance-Monitoring**: API-Aufruf-Optimierung
- **Audit-Trail**: BenutzeraktivitÃ¤ten nachverfolgbar

## ğŸ¤ Contributing

1. Fork des Repositories
2. Feature-Branch erstellen (`git checkout -b feature/AmazingFeature`)
3. Ã„nderungen committen (`git commit -m 'Add some AmazingFeature'`)
4. Branch pushen (`git push origin feature/AmazingFeature`)
5. Pull Request erstellen

## ğŸ“ Lizenz

Dieses Projekt steht unter der MIT-Lizenz. Siehe `LICENSE` Datei fÃ¼r Details.

## ğŸ™ Danksagungen

- OpenAI fÃ¼r GPT-4o-mini API
- Flask-Community fÃ¼r das excellente Framework
- Bootstrap fÃ¼r das responsive UI-Framework
- Alle Contributor und Tester